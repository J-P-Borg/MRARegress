% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Score.R
\name{Score}
\alias{Score}
\title{"Score" :  Delivers the "Confusion Matrix" when a reference is available.}
\usage{
Score(Ret, Ref, Classes = NULL, Verbose = FALSE, NoPrint = FALSE)
}
\arguments{
\item{Ret}{list of informations delivered by "Classify" or matrix of integers or discrete values (letters, strings).
If 'Ret' is a list of informations delivered by "Classify", Score uses 'Ret$rDig' (connectivity matrix classified) and 'Ret$Input$Classes' (classes) and
the parameter 'Classes' is ignored.
If 'Ret' is a matrix of numbers, the parameter 'Classes' is mandatory.}

\item{Ref}{Matrix of integers or discrete values    The "Reference Matrix".}

\item{Classes}{Vector        A vector showing the classes (for instance: c(0,1)). Default value : NULL.}

\item{Verbose}{Logical        Default    value : FALSE.
If TRUE, additional printings are made. These printings are for internal use only, so they are not documented.}

\item{NoPrint}{Logical        Default    value : FALSE.
If TRUE, no printings are made. Useful for tests including calls to 'MRARegress' in a loop.}
}
\value{
\if{html}{\out{<div class="sourceCode">}}\preformatted{List	NULL in case of error or a list containing the "Confusion Matrix", classical scoring coefficients and the Input values.
}\if{html}{\out{</div>}}
}
\description{
: this function computes the "Confusion Matrix" (CM) by comparing the "Classified Connectivity Matrix" delivered by MRARegress::Classify with the "Reference".\cr
If Nc is the number of classes, the "Confusion Matrix" has Nc rows and Nc columns. The rows correspond to the "Reference" values and the columns, to the classified values (rDig)\cr
CM[i, j] = number of classified coefficients equal to "j-1", while the corresponding reference coefficients are equal to "i-1" (i, j >= 1).\cr
For instance, if "Classes = c(0, 1)", then:\cr
-  CM[1, 1] = TN  ("True Negative"),\cr
-  CM[1, 2] = FP  ("False Positive"),\cr
-  CM[2, 1] = FN  ("False Negative"),\cr
-  CM[2, 2] = TP  ("True Positive").\cr
Ti (number of "i" discovered that belong really to class 'i'), Fi (number of "i" discovered that don't belong to class 'i'),
Precision_i or Accuracy_i (Ti/NDi), Recall_i (Ti/NRi). PrecisionMC = (∑_(i=1)^n▒〖Precision_i〗)⁄n. RecallMC = (∑_(i=1)^n▒〖Recall_i〗)⁄n   (n : number of classes) and
F1 score (2\emph{precision}recall/(precision+recall)) combining precision and recall (MC means "Multi Class"). **MC is also called 'Balanced **'.
If "Classes = c(0, 1)" : precision (TP/ND1), sensitivity (or sensibility or recall: TP/NR1), specificity (TN/NR0).
In this case, NR1 is also called "P" and NR0 s called "N".
All these values, suffixed by '_de', mean 'Diagonal Excluded'.

Computes many scoring coefficients
The input data are described above and the outputs below.
}
\details{
\if{html}{\out{<div class="sourceCode">}}\preformatted{If there are two classes (for instance: c(0,1)), Se(nsitivity) is also called 'Sensibility', 'Recall', 'Hit Rate' or 'TPR' (True Positive Rate), Se =TP/P,
Sp(ecificity), 'Selectivity' or 'TNR' (TrueNegative Rate), Sp=TN/N, where P = NR1 and N = NR0,
Dst (Distance to the diagonal) Dst = Se+Sp-1, Pr(ecision) Pr=TP/(TP+FP).
We use also 1- Sp = FP/N  (Probability that a true negative will be declared positive). Also referred to as False Positive Rate (FPR) or False Positive Fraction (FPF) or Value (FPV)

Imported libraries :
	- upstartr	to use "unaccent"
}\if{html}{\out{</div>}}

OUTPUT:

\if{html}{\out{<div class="sourceCode">}}\preformatted{ConfMat		the 'Confusion Matrix'
Scores		the 'scoring coefficients' :  NRi, NDi, Ti, Fi, PrecisionMC, RecallMC, F1MC score (2*PrecisionMC*RecallMC/(PrecisionMC+RecallMC))
Scores2		the 'scoring coefficients' if nbr. of classes = 2 (else : NULL) : Se, Sp, FPR, Dst, Pr, F1
Input		List	list of the input parameters values. NULL values are not replaced.
}\if{html}{\out{</div>}}
}
