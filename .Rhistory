for (i in 2:ll) {								# nn[1] = "(Intercept)"
rij[1, nn[i]] <- forward$coefficients[nn[i]]
}
}
if (Verbose) {
cat (" ll ", ll, " nn ", nn, " rij ", rij, "\n")
}
return(rij[1, ])
},		# expr
error = function (e) {
message ("Error detected in STEP method !")
print(e)
}		# error
)			# tryCatch
return (NULL)
}		# fSTEP
#' Computes the "Connectivity Matrix" using Random Forest Method (library randomForest)
#'
#'@param MatU		Used to compute linear Regression
#'@param MatY		Y as a function of U
#'@param seqLetters	A sequence of lower case letters "a", "b" .... used to name the columns
#'@param nbN		Number of nodes
#'
#'
#' @return 			NULL if an error is detected or the result ("r[iNode, ]") otherwise  (vector, length = nbN-1)
#'
fRForest	<- function (MatU, MatY, seqLetters, nbN) {
tryCatch (
expr = {
rL 			<- vector(length=nbN-1)					# Result of Random Forest method
nbLmin		<- 80									# minimum number of rows to use Random Forest method
MatA		<- cbind(MatY, MatU)
nr			<- nrow(MatA)
nrep		<- round(nbLmin/nr)
MatB		<- MatA
if (nrep > 1) {
for (i in 1:nrep) {									# to have enough rows
MatB	<- rbind(MatB, MatA)
}
}
colnames(MatB)	<- c("Y", seqLetters)
rf			<- randomForest(Y ~ ., data=MatB, importance=TRUE)
rL			<- importance(rf)[,1]/sum(abs(importance(rf)[,1]))
return (rL)
},		# expr
error = function (e) {
message ("Error detected in Random Forest method !")
print(e)
}		# error
)			# tryCatch
return (NULL)
}		# fRForest
#' Computes a sequence of letters : "a", "b", "c", ...., "z", "aa", "ab", .... , "az", "ba", "bb" etc ....
#'
#'@param	n		The number of elements of the sequence
#'
#'
#' @return			A vector, length n, containing the sequence of letters
#'
sequence_letters <- function(n) {
tryCatch (
expr = {
seq <- character(n)
letters <- c(letters, "")
for (i in 1:n) {
indices <- c()
k <- i - 1
while (k >= 0) {
indices <- c((k %% 26) + 1, indices)
k <- k %/% 26 - 1
}
seq[i] <- paste0(letters[indices], collapse = "")
}
return(seq)
},		# expr
error = function (e) {
message ("Error detected in sequence_letters function!")
print(e)
}		# error
)			# tryCatch
return (NULL)
}		# sequence_letters
#' Computes a squared value
#'
#'@param	x		The value to square (may be a vector)
#'
#'
#' @return			A vector, with the values squared
#'
fcarre	= function(x) {x^2}
Tst_Knowledge_3		<- function (iCalc) {
iFic	<-	(iCalc-1) %/% nbPcKV +1				# Index of the file studied
iKV		<-	(iCalc-1) %%  nbPcKV +1				# Index of the KV percentage studied
nbKV 	<- round(PcKV[iKV]*TA / 100)			# Nbr of known nodes
MatExp		<- matrix(nrow=nbN, ncol=nbK*nbN+1)	# Unitary matrices
Solution	<- matrix(nrow=nbN, ncol=nbN)
Result1		<- vector(length=nbD+1)				# To store unit results, plus last seed
KnlM		<- matrix(nrow=nbN, ncol=nbN)		# The known values
MatDif		<- matrix(nrow=2, ncol=nbN*nbN)		# To compute the score
MatExp[ , ]		<- MatExpG[ , ,iFic,iT]
Solution[ , ]	<- SolG	  [ , ,iFic]
MatDif[1, ]		<- Solution[ , ]
if (nbKV == 0)	{								# Only one trial in this case
Ret		<- MRARegress (MatExp, PertG, NoPrint=TRUE)
MatDif[2, ]	<- Ret$r
for (iDraw in 1:nbD)
Result1[iDraw]	<- dist(MatDif)
Result1[nbD+1]	<- 0						# No seed value in this case
} else {
set.seed(12345)								#	To get the same sequence of random numbers
for (iDraw in 1:nbD) {						# 	nbD simulations
#	Choice of the nodes to be indicated to the program
KnlM[ , ]	<- "x"
A	<- sample (1:TA, nbKV)
for (idx in A) {
KnlM[ ,TF+idx]	<- 0
}
Ret		<- MRARegress (MatExp, PertG, KnlgMap=KnlM, Hyp_Cvx=HCvx, NoPrint=TRUE)
MatDif[2, ]	<- Ret$r
Result1[iDraw]	<- dist(MatDif)
}		# Loop on simulations (iDraw)
Result1[nbD+1]	<-	.Random.seed			# To allow for further simulations, if necessary
}
return (Result1)
}		# Tst_Knowledge_3
vRoot		<- "C:/Users/jean-pierre.borg/IRCM/These/Recherche/Packages/MRAregress/data/"
vRootFig	<- "C:/Users/jean-pierre.borg/IRCM/Publications/Article 2/Figures/"
Sets		<-	c(9, 10, 11)	# vs c(9, 10, 11, 12)
Sets=c(9)
nbSets		<- length(Sets)
nbFics		<-  5				# Nbr of files by set of values
nbK			<-	2				# Nbr of perturbations (KO, KD -50%)
nbD			<- 10				# Number of trials
Noises		<- c(0.1, 0.5)		# Error coefficients
Noises=c(1)
nbT			<- length(Noises)
PcKV		<- seq(0, 100, by=20)							# Percentage of known TA nodes
PcKV=seq(0,40,by=20)
nbPcKV		<- length(PcKV)
HCvx		<- 0.1											# KnlgMap\[i,j\] =  "1" means r\[i,j\] >=  HCvx  -- not used here
Result1G	<- array(0, dim=c(nbD+1, nbPcKV, nbSets, nbFics, nbT))		# To store unit results
Results		<- array(0, dim=c(2, 	 nbPcKV, nbSets, nbT))				# To store averaged results
dimnames (Results)	<- list (c("Mean", "Std"), PcKV, Sets, Noises)
Res.df		<- data.frame(pc=NULL, dd=NULL, ddP=NULL, ddM=NULL, Set=NULL, Noise=NULL)	# To draw Figure "Euclidian Distance between computed matrix and solution = f(% known TA nodes)"
val			<- paste(vRoot, "FileNbr.csv", sep="")
FileNbr		<- as.matrix(fread(val, data.table=F, header=T), ncol=nbFics+2)
# Column name	: TF 	TA    1 	 2 	   3 	 4 	   5
# First row		: Seed	 	12345 72090 87577 45648 16637
# Following rows: TF val TA val File nbrs
Ncpus		<- parallel::detectCores()			# Number of cores : 20 in my PC
Ncpus		<- min(Ncpus, 15)					# To prevent the PC from overheating
cat ("START FRANK networks !", as.character(Sys.time()), "\n")
for (iSet in 1:nbSets) {
Set			<- Sets[iSet]
TF			<- as.numeric(FileNbr[Set, 1])
TA			<- as.numeric(FileNbr[Set, 2])
nbN			<- TF+TA
MatExpG		<- array(0, dim=c(nbN, nbK*nbN+1, nbFics, nbT))		# MatExp, for all files of the set
SolG		<- array(0, dim=c(nbN, nbN, nbFics))					# Solution, for all files of the set
PertG		<- vector(length=nbK*nbN+1)								# Perturbation, for all files of the set
for (iFic in 1:nbFics) {
valR	<- paste(vRoot, "Frank_TF", TF, "_TA", TA, "_", iFic, "_Sol.rda", sep="")
load (valR)				# Solution
SolG[ , ,iFic]				<-  Solution
for (iT in 1:nbT) {
valR	<- paste(vRoot, "Frank_TF", TF, "_TA", TA, "_", iFic, "_R", iT, ".rda", sep="")
load (valR)				# MatRN2
Res		<- MatR2MatExp	(MatRN2, nbN, nbK)		# software utility, to get the data in the format expected by MRARegress
MatExpG[ , ,iFic,iT]	<- Res$Exp
PertG  					<- Res$Pert				# PertG doesn't depend on iT or iFic (not useful to use an array)
}	# Loop iT
}		# loop iFic
for (iT in 1:nbT)	{
cat (" Set TF ", TF, " TA ", TA, " Noise ", Noises[iT]," at : ", as.character(Sys.time()), "\n")
cl	<- parallel::makeCluster(Ncpus)		# Start parallel computing
doParallel::registerDoParallel(cl)
Result1G[ , ,iSet, ,iT]		<- foreach (iCalc = 1:(nbFics*nbPcKV), .combine='cbind') %dopar% {
Tst_Knowledge_3(iCalc)
}
parallel::stopCluster(cl)
for (iKV in 1:nbPcKV) {
Results["Mean",iKV,iSet,iT]		<- mean	(Result1G [1:nbD,iKV,iSet, ,iT])
Results["Std", iKV,iSet,iT]		<- sd	(Result1G [1:nbD,iKV,iSet, ,iT])
moy		<- Results["Mean",iKV,iSet,iT]
std		<- Results["Std", iKV,iSet,iT]
Res.tmp.df	<- data.frame(pc=PcKV[iKV], dd=moy, ddP=moy+std, ddM=moy-std, Set=iSet, Noise=iT)
Res.df		<- rbind(Res.df, Res.tmp.df)
}		# Loop on percentage (iKV)
}			# Loop iT
}				# loop iSet
cat ("Done !", as.character(Sys.time()), "\n")
Results
vRoot		<- "C:/Users/jean-pierre.borg/IRCM/These/Recherche/Packages/MRAregress/data/"
vRootFig	<- "C:/Users/jean-pierre.borg/IRCM/Publications/Article 2/Figures/"
Sets		<-	c(9, 10, 11)	# vs c(9, 10, 11, 12)
nbSets		<- length(Sets)
nbFics		<-  5				# Nbr of files by set of values
nbK			<-	2				# Nbr of perturbations (KO, KD -50%)
nbD			<- 10				# Number of trials
Noises		<- c(0.1, 0.5)		# Error coefficients
nbT			<- length(Noises)
PcKV		<- seq(0, 100, by=20)							# Percentage of known TA nodes
nbPcKV		<- length(PcKV)
HCvx		<- 0.1											# KnlgMap\[i,j\] =  "1" means r\[i,j\] >=  HCvx  -- not used here
Result1G	<- array(0, dim=c(nbD+1, nbPcKV, nbSets, nbFics, nbT))		# To store unit results
Results		<- array(0, dim=c(2, 	 nbPcKV, nbSets, nbT))				# To store averaged results
dimnames (Results)	<- list (c("Mean", "Std"), PcKV, Sets, Noises)
Res.df		<- data.frame(pc=NULL, dd=NULL, ddP=NULL, ddM=NULL, Set=NULL, Noise=NULL)	# To draw Figure "Euclidian Distance between computed matrix and solution = f(% known TA nodes)"
val			<- paste(vRoot, "FileNbr.csv", sep="")
FileNbr		<- as.matrix(fread(val, data.table=F, header=T), ncol=nbFics+2)
# Column name	: TF 	TA    1 	 2 	   3 	 4 	   5
# First row		: Seed	 	12345 72090 87577 45648 16637
# Following rows: TF val TA val File nbrs
Ncpus		<- parallel::detectCores()			# Number of cores : 20 in my PC
Ncpus		<- min(Ncpus, 15)					# To prevent the PC from overheating
cat ("START FRANK networks !", as.character(Sys.time()), "\n")
for (iSet in 1:nbSets) {
Set			<- Sets[iSet]
TF			<- as.numeric(FileNbr[Set, 1])
TA			<- as.numeric(FileNbr[Set, 2])
nbN			<- TF+TA
MatExpG		<- array(0, dim=c(nbN, nbK*nbN+1, nbFics, nbT))		# MatExp, for all files of the set
SolG		<- array(0, dim=c(nbN, nbN, nbFics))					# Solution, for all files of the set
PertG		<- vector(length=nbK*nbN+1)								# Perturbation, for all files of the set
for (iFic in 1:nbFics) {
valR	<- paste(vRoot, "Frank_TF", TF, "_TA", TA, "_", iFic, "_Sol.rda", sep="")
load (valR)				# Solution
SolG[ , ,iFic]				<-  Solution
for (iT in 1:nbT) {
valR	<- paste(vRoot, "Frank_TF", TF, "_TA", TA, "_", iFic, "_R", iT, ".rda", sep="")
load (valR)				# MatRN2
Res		<- MatR2MatExp	(MatRN2, nbN, nbK)		# software utility, to get the data in the format expected by MRARegress
MatExpG[ , ,iFic,iT]	<- Res$Exp
PertG  					<- Res$Pert				# PertG doesn't depend on iT or iFic (not useful to use an array)
}	# Loop iT
}		# loop iFic
for (iT in 1:nbT)	{
cat (" Set TF ", TF, " TA ", TA, " Noise ", Noises[iT]," at : ", as.character(Sys.time()), "\n")
cl	<- parallel::makeCluster(Ncpus)		# Start parallel computing
doParallel::registerDoParallel(cl)
Result1G[ , ,iSet, ,iT]		<- foreach (iCalc = 1:(nbFics*nbPcKV), .combine='cbind') %dopar% {
Tst_Knowledge_3(iCalc)
}
parallel::stopCluster(cl)
for (iKV in 1:nbPcKV) {
Results["Mean",iKV,iSet,iT]		<- mean	(Result1G [1:nbD,iKV,iSet, ,iT])
Results["Std", iKV,iSet,iT]		<- sd	(Result1G [1:nbD,iKV,iSet, ,iT])
moy		<- Results["Mean",iKV,iSet,iT]
std		<- Results["Std", iKV,iSet,iT]
Res.tmp.df	<- data.frame(pc=PcKV[iKV], dd=moy, ddP=moy+std, ddM=moy-std, Set=iSet, Noise=iT)
Res.df		<- rbind(Res.df, Res.tmp.df)
}		# Loop on percentage (iKV)
}			# Loop iT
}				# loop iSet
save(Results,  file="C:/Users/jean-pierre.borg/IRCM/Publications/Article 2/Figures/Fig8.rda")
save(Res.df,   file="C:/Users/jean-pierre.borg/IRCM/Publications/Article 2/Figures/Fig8df.rda")
save(Result1G, file="C:/Users/jean-pierre.borg/IRCM/Publications/Article 2/Figures/Fig8_Result1G.rda") 	# To allow for further simulations, if necessary
cat ("Done !", as.character(Sys.time()), "\n")
Results
Result1G
NomFic 		<- paste(vRootFig, "Fig9a.pdf", sep="")
Res1.df		<- subset(Res.df, Noise == 1)
Res1_1.df	<- subset(Res1.df, Set == 9)			# TF30,  TA30
Res1_2.df	<- subset(Res1.df, Set == 10)			# TF50,  TA50
Res1_3.df	<- subset(Res1.df, Set == 11)			# TF100, TA100
pdf(file=NomFic)
ggplot() +
geom_line(data=Res1.df, aes(x=pc, y=dd, colour=factor(Set))) +
xlab("% known TA nodes") + ylab("Average distance between Solution and Calculated Matrix") + ggtitle("Dist. between Solution and Calculated Matrix : \nFRANK  TA = TF = 30, 50, 100, medium noise (k = 0.1)") +
scale_colour_manual(name="Set", values=c("1"="blue", "2"="chartreuse1", "3"="brown3")) +
geom_ribbon(data=Res1_1.df, aes(x=pc, ymin=ddM, ymax=ddP), fill="cadetblue1", 		alpha=0.3) +		# Ribbon around a "blue" line
geom_ribbon(data=Res1_2.df, aes(x=pc, ymin=ddM, ymax=ddP), fill="darkolivegreen3", alpha=0.3) +		# Ribbon around a "chartreuse1" line
geom_ribbon(data=Res1_3.df, aes(x=pc, ymin=ddM, ymax=ddP), fill="chocolate1", 		alpha=0.3) +		# Ribbon around a "brown3" line
theme(axis.text.x = element_text(color="black")) +
theme(axis.text.y = element_text(color="black")) +
theme(text = element_text(size = 10))
dev.off()
NomFic 		<- paste(vRootFig, "Fig9b.pdf", sep="")
Res2.df		<- subset(Res.df, Noise == 2)
Res2_1.df	<- subset(Res2.df, Set == 9)			# TF30,  TA30
Res2_2.df	<- subset(Res2.df, Set == 10)			# TF50,  TA50
Res2_3.df	<- subset(Res2.df, Set == 11)			# TF100, TA100
pdf(file=NomFic)
ggplot() +
geom_line(data=Res2.df, aes(x=pc, y=dd, colour=factor(Set))) +
xlab("% known TA nodes") + ylab("Average distance between Solution and Calculated Matrix") + ggtitle("Dist. between Solution and Calculated Matrix : \nFRANK  TA = TF = 30, 50, 100, strong noise (k = 0.5)") +
scale_colour_manual(name="Set", values=c("1"="blue", "2"="chartreuse1", "3"="brown3")) +
geom_ribbon(data=Res2_1.df, aes(x=pc, ymin=ddM, ymax=ddP), fill="cadetblue1", 		alpha=0.3) +		# Ribbon around a "blue" line
geom_ribbon(data=Res2_2.df, aes(x=pc, ymin=ddM, ymax=ddP), fill="darkolivegreen3", alpha=0.3) +		# Ribbon around a "chartreuse1" line
geom_ribbon(data=Res2_3.df, aes(x=pc, ymin=ddM, ymax=ddP), fill="chocolate1", 		alpha=0.3) +		# Ribbon around a "brown3" line
theme(axis.text.x = element_text(color="black")) +
theme(axis.text.y = element_text(color="black")) +
theme(text = element_text(size = 10))
dev.off()
Res.df
NomFic 		<- paste(vRootFig, "Fig9a.pdf", sep="")
Res1.df		<- subset(Res.df, Noise == 1)
Res1_1.df	<- subset(Res1.df, Set == 1)			# TF30,  TA30
Res1_2.df	<- subset(Res1.df, Set == 2)			# TF50,  TA50
Res1_3.df	<- subset(Res1.df, Set == 3)			# TF100, TA100
pdf(file=NomFic)
ggplot() +
geom_line(data=Res1.df, aes(x=pc, y=dd, colour=factor(Set))) +
xlab("% known TA nodes") + ylab("Average distance between Solution and Calculated Matrix") + ggtitle("Dist. between Solution and Calculated Matrix : \nFRANK  TA = TF = 30, 50, 100, medium noise (k = 0.1)") +
scale_colour_manual(name="Set", values=c("1"="blue", "2"="chartreuse1", "3"="brown3")) +
geom_ribbon(data=Res1_1.df, aes(x=pc, ymin=ddM, ymax=ddP), fill="cadetblue1", 		alpha=0.3) +		# Ribbon around a "blue" line
geom_ribbon(data=Res1_2.df, aes(x=pc, ymin=ddM, ymax=ddP), fill="darkolivegreen3", alpha=0.3) +		# Ribbon around a "chartreuse1" line
geom_ribbon(data=Res1_3.df, aes(x=pc, ymin=ddM, ymax=ddP), fill="chocolate1", 		alpha=0.3) +		# Ribbon around a "brown3" line
theme(axis.text.x = element_text(color="black")) +
theme(axis.text.y = element_text(color="black")) +
theme(text = element_text(size = 10))
dev.off()
NomFic 		<- paste(vRootFig, "Fig9b.pdf", sep="")
Res2.df		<- subset(Res.df, Noise == 2)
Res2_1.df	<- subset(Res2.df, Set == 1)			# TF30,  TA30
Res2_2.df	<- subset(Res2.df, Set == 2)			# TF50,  TA50
Res2_3.df	<- subset(Res2.df, Set == 3)			# TF100, TA100
pdf(file=NomFic)
ggplot() +
geom_line(data=Res2.df, aes(x=pc, y=dd, colour=factor(Set))) +
xlab("% known TA nodes") + ylab("Average distance between Solution and Calculated Matrix") + ggtitle("Dist. between Solution and Calculated Matrix : \nFRANK  TA = TF = 30, 50, 100, strong noise (k = 0.5)") +
scale_colour_manual(name="Set", values=c("1"="blue", "2"="chartreuse1", "3"="brown3")) +
geom_ribbon(data=Res2_1.df, aes(x=pc, ymin=ddM, ymax=ddP), fill="cadetblue1", 		alpha=0.3) +		# Ribbon around a "blue" line
geom_ribbon(data=Res2_2.df, aes(x=pc, ymin=ddM, ymax=ddP), fill="darkolivegreen3", alpha=0.3) +		# Ribbon around a "chartreuse1" line
geom_ribbon(data=Res2_3.df, aes(x=pc, ymin=ddM, ymax=ddP), fill="chocolate1", 		alpha=0.3) +		# Ribbon around a "brown3" line
theme(axis.text.x = element_text(color="black")) +
theme(axis.text.y = element_text(color="black")) +
theme(text = element_text(size = 10))
dev.off()
str(Results)
OldResults=Results
OldRes.df=Res.df
Results
Results[1, ,1, 1] = c(0.53807802, 2.9987616, 4.1641022, 5.032817, 5.629236,   0)
Results[2, ,1, 1] = c(0.08544347, 0.6785271, 0.9722276, 1.191689, 1.372688,   0)
Results[1, ,1, 1] = c(0.53807802, 0.47931241, 0.42105042, 0.36076668, 0.3017738,   0)
Results[2, ,1, 1] = c(0.08544347, 0.07402877, 0.05671406, 0.04687009, 0.0337981,   0)
Results[1, ,2, 1] = c(1.0353508, 0.9049661, 0.7676512, 0.62839205, 0.48523493,   0)
Results[2, ,2, 1] = c(0.1908226, 0.1543061, 0.1188528, 0.09210166, 0.08504167,   0)
Results[1, ,3, 1] = c(1.4007063, 1.2159082, 1.0310414, 0.84351896, 0.65077541,   0)
Results[2, ,3, 1] = c(0.2426198, 0.1921912, 0.1415155, 0.08545041, 0.02780376,   0)
Results[1, ,1, 2] = c(2.5157277, 2.2024860, 1.9067644, 1.6085473, 1.3314153,   0)
Results[2, ,1, 2] = c(0.4109394, 0.3443972, 0.2604825, 0.2141473, 0.1614541,   0)
Results[1, ,2, 2] = c(4.5994789, 3.9926712, 3.3858568, 2.7931957, 2.1906105,   0)
Results[2, ,2, 2] = c(0.7315105, 0.6155399, 0.5076789, 0.4252225, 0.3289608 ,  0)
Results[1, ,3, 2] = c( 6.2720540, 5.3615645, 4.507470, 3.6680857, 2.8150817,   0)
Results[2, ,3, 2] = c( 0.8457015, 0.7125749, 0.606942, 0.5063534, 0.4060037,   0)
Sets
OldSets=Sets
Sets=c(1,2,3)
Results
dimnames (Results)	<- list (c("Mean", "Std"), PcKV, Sets, Noises)
Results
Res.df
OldRes.df
Res.df		<- data.frame(pc=NULL, dd=NULL, ddP=NULL, ddM=NULL, Set=NULL, Noise=NULL)
Res.df
for (iSet in 1:3) {
for (iT in 1:2) {
for (iKV in 1:nbPcKV) {
moy		<- Results["Mean",iKV,iSet,iT]
std		<- Results["Std", iKV,iSet,iT]
Res.tmp.df	<- data.frame(pc=PcKV[iKV], dd=moy, ddP=moy+std, ddM=moy-std, Set=iSet, Noise=iT)
Res.df		<- rbind(Res.df, Res.tmp.df)
}		# Loop on percentage (iKV)
}			# Loop iT
}				# loop iSet
Res.df
save(Results,  file="C:/Users/jean-pierre.borg/IRCM/Publications/Article 2/Figures/Fig8.rda")
save(Res.df,   file="C:/Users/jean-pierre.borg/IRCM/Publications/Article 2/Figures/Fig8df.rda")
Res1.df		<- subset(Res.df, Noise == 1)
Res1_1.df	<- subset(Res1.df, Set == 1)			# TF30,  TA0
Res1_2.df	<- subset(Res1.df, Set == 2)			# TF60,  TA0
Res1_3.df	<- subset(Res1.df, Set == 3)			# TF100, TA0
ggplot() +
geom_line(data=Res1.df, aes(x=pc, y=dd, colour=factor(Set))) +
xlab("% known values") + ylab("Average distance between Solution and Calculated Matrix") + ggtitle("Dist. between Solution and Calculated Matrix : \nFRANK  TF = 30, 60, 100, TA = 0, medium noise (k = 0.1)") +
scale_colour_manual(name="Set", values=c("1"="blue", "2"="chartreuse1", "3"="brown3")) +
geom_ribbon(data=Res1_1.df, aes(x=pc, ymin=ddM, ymax=ddP), fill="cadetblue1", 		alpha=0.3) +		# Ribbon around a "blue" line
geom_ribbon(data=Res1_2.df, aes(x=pc, ymin=ddM, ymax=ddP), fill="darkolivegreen3", alpha=0.3) +		# Ribbon around a "chartreuse1" line
geom_ribbon(data=Res1_3.df, aes(x=pc, ymin=ddM, ymax=ddP), fill="chocolate1", 		alpha=0.3) +		# Ribbon around a "brown3" line
theme(axis.text.x = element_text(color="black")) +
theme(axis.text.y = element_text(color="black")) +
theme(text = element_text(size = 10))
Res2.df		<- subset(Res.df, Noise == 2)
Res2_1.df	<- subset(Res2.df, Set == 1)			# TF30,  TA0
Res2_2.df	<- subset(Res2.df, Set == 2)			# TF60,  TA0
Res2_3.df	<- subset(Res2.df, Set == 3)			# TF100, TA0
ggplot() +
geom_line(data=Res2.df, aes(x=pc, y=dd, colour=factor(Set))) +
xlab("% known values") + ylab("Average distance between Solution and Calculated Matrix") + ggtitle("Dist. between Solution and Calculated Matrix : \nFRANK  TF = 30, 60, 100, TA = 0, strong noise (k = 0.5)") +
scale_colour_manual(name="Set", values=c("1"="blue", "2"="chartreuse1", "3"="brown3")) +
geom_ribbon(data=Res2_1.df, aes(x=pc, ymin=ddM, ymax=ddP), fill="cadetblue1", 		alpha=0.3) +		# Ribbon around a "blue" line
geom_ribbon(data=Res2_2.df, aes(x=pc, ymin=ddM, ymax=ddP), fill="darkolivegreen3", alpha=0.3) +		# Ribbon around a "chartreuse1" line
geom_ribbon(data=Res2_3.df, aes(x=pc, ymin=ddM, ymax=ddP), fill="chocolate1", 		alpha=0.3) +		# Ribbon around a "brown3" line
theme(axis.text.x = element_text(color="black")) +
theme(axis.text.y = element_text(color="black")) +
theme(text = element_text(size = 10))
load("C:/Users/jean-pierre.borg/IRCM/These/Recherche/Packages/MRARegress/data/Frank_TF100_TA0_1_R1.rda")
View(MatRN2)
load("C:/Users/jean-pierre.borg/IRCM/These/Recherche/Packages/MRARegress/data/Frank_TF100_TA0_1_R2.rda")
load("C:/Users/jean-pierre.borg/IRCM/These/Recherche/Packages/MRARegress/data/Frank_TF100_TA0_1_Sol.rda")
load("C:\\Users\\jean-pierre.borg\\IRCM\\These\\Recherche\\Packages\\MRAregress\\data\\Frank_TF100_TA0_1_R1.rda")
rm(list = ls())
load("C:\\Users\\jean-pierre.borg\\IRCM\\These\\Recherche\\Packages\\MRAregress\\data\\Frank_TF100_TA0_1_R1.rda")
load("C:\\Users\\jean-pierre.borg\\IRCM\\These\\Recherche\\Packages\\MRAregress\\data\\Frank_TF300_TA0_1_R1.rda")
load("C:\\Users\\jean-pierre.borg\\IRCM\\These\\Recherche\\Packages\\MRAregress\\data-raw\\Frank_TF100_TA0_1_R1.rda")		#	MatRN2,   bruit 10%
MatRN100	<- MatRN2
save(MatRN100, file="C:\\Users\\jean-pierre.borg\\IRCM\\These\\Recherche\\Packages\\MRAregress\\data\\Frank_TF100_TA0_1_R1.rda")	# MatRN100
rm(list = ls())
load("C:/Users/jean-pierre.borg/IRCM/These/Recherche/Packages/MRARegress/data/Frank_TF100_TA0_1_R1.rda")
vRoot		<- "C:/Users/jean-pierre.borg/IRCM/Publications/BioInformatics/MRA_Regression_ed1/Vers_Rev1/Donnees/FRANK2/"
val			<- paste(vRoot, "FileNbr.csv", sep="")
FileNbr		<- as.matrix(fread(val, data.table=F, header=T), ncol=NBFiles+2)
library(data.table)
val			<- paste(vRoot, "FileNbr.csv", sep="")
FileNbr		<- as.matrix(fread(val, data.table=F, header=T), ncol=NBFiles+2)
FileNbr
save(FileNbr, file="C:\\Users\\jean-pierre.borg\\IRCM\\These\\Recherche\\Packages\\MRAregress\\data\\Frank_FileNbr.rda")
str(FileNbr)
library(MRARegress)
load ("C:/Users/jean-pierre.borg/IRCM/These/Recherche/Packages/MRARegress/data/Frank_TF30_TA30_1_R1.rda")
rm(list = ls())		# We have also to restart a new session to unload all the packages.
# We can also detach every package individually by : detach(package:packagename)
# ComplÃ©ter par "Restart R"
library('MRARegress')		# Ne pas activer cette librairie si on modifie "MRARegress"
library('stringr')
library('RCy3')
library ("foreach")			#	To use foreach
library ("doParallel")		#	To use doParallel
library('CVXR')				#	To use convexity
library('upstartr')			#	To use unaccent
library ("data.table")
vRoot		<- "C:/Users/jean-pierre.borg/IRCM/These/Recherche/Packages/MRAregress/data/"
vRootFig	<- "C:/Users/jean-pierre.borg/IRCM/Publications/Article 2/Figures/"
load (paste(vRoot, "Perturb_10.rda", sep=""))		#   Perturb_10
Fics		<- c("10_1", "10_2", "10_3", "10_4", "10_5")		# Files to study
nbFics		<- length(Fics)
Res.df		<- data.frame(pc=NULL, dd=NULL, ddP=NULL, ddM=NULL, Fic=NULL)	# 	To draw Figure "Dist to diagonal of the computed matrix = f(% known values)"
PcKV		<- seq(0, 100, by=20)				# 	Percentage of known values
nbPcKV		<- length(PcKV)
HCvx		<- 0.5								#	KnlgMap\[i,j\] =  "1" means r\[i,j\] >=  HCvx
nbK			<- 2								#   nbK corresponds to the number of perturbation types (KO or KD)
nbN			<- 10								# 	nbN : number of nodes
nbD			<- 20								# 	Number of trials
Result1		<- vector(length=nbD)				#	To store unit results
Results		<- array(0, dim=c(2,nbPcKV,nbFics))	#	To store averaged results
dimnames (Results)	<- list (c("Mean", "Std"), PcKV, Fics)
Diag		<- NULL
for (i in 1:nbN) {
Diag	<- cbind (Diag, (i-1)*nbN + i)		#	Position of the diagonal elements
}
NDiag		<- seq (1, nbN*nbN, by=1)			# 	Index of terms not belonging to the diagonal
NDiag		<- NDiag[-Diag]
KnlM		<- matrix("x", nrow=nbN, ncol=nbN)	#	The known values
cat ("START 10 nodes networks !", as.character(Sys.time()), "\n")
for (iFic in 1:nbFics) {
load (paste(vRoot, "MatExp_",   Fics[iFic], ".rda", sep=""))		#   MatExp
load (paste(vRoot, "Solution_", Fics[iFic], ".rda", sep=""))		#   Solution
for (iKV in 1:nbPcKV) {
nbKV 	<- round(PcKV[iKV]*nbN*(nbN-1) / 100)	# Nbr of known values
namKV 	<- as.character(PcKV[iKV])
set.seed(12345)								#	To get the same sequence of random numbers
for (iDraw in 1:nbD) {						# 	nbD simulations
#	Choice of the values to be indicated to the program
KnlM[ , ]	<- "x"
if (nbKV > 0) {
A	<- sample (NDiag, nbKV)
for (idx in A) {
KnlM[idx]	<- ifelse(Solution[idx] == 1, 1, 0)
}
}
Ret		<- MRARegress (MatExp, Perturb_10, KnlgMap=KnlM, Hyp_Cvx=HCvx, NoPrint=TRUE)
Res		<- Score (Classify(Ret, NoPrint=TRUE), Solution, NoPrint=TRUE)$Scores2$Dst
Result1[iDraw]	<- Res
#			cat (namKV, "% -- Dst : ", Res, "\n")
}		# Loop on simulations (iDraw)
Results["Mean", iKV, iFic]		<- mean(Result1)
Results["Std",  iKV, iFic]		<- sd(Result1)
cat ("File ", paste("InSilico_", Fics[iFic], sep=""), " Percent : ", namKV, " Mean : ", Results["Mean", iKV, iFic], " Std : ", Results["Std", iKV, iFic], "\n")
Res.tmp.df	<- data.frame(pc=PcKV[iKV], dd=mean(Result1), ddP=mean(Result1)+sd(Result1), ddM=mean(Result1)-sd(Result1), Fic=Fics[iFic])
Res.df		<- rbind(Res.df, Res.tmp.df)
}		# Loop on knowledge percentage (iKV)
cat ("\n")
}			# Loop on Fics (iFic)
?MRARegress
?MRARegress
library(MRARegress)
?MRARegress
library(MRARegress)
?MRARegress
library(MRARegress)
?MRARegress
?Score
?Classify
?DrawGraph
library(MRARegress)
?MRARegress
?Score
?Classify
?DrawGraph
?DrawGraphML
library(MRARegress)
?Classify
?DrawGraph
?DrawGraphML
?DrawGraph
?Classify
?DrawGraph
?DrawGraphML
library(MRARegress)
?DrawGraphML
